{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2759c7-165c-4812-bfa7-625737dd7512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Module\n",
    "from brevitas.nn import QuantLinear\n",
    "from brevitas.nn import QuantReLU\n",
    "from brevitas.nn import QuantIdentity\n",
    "from brevitas.nn import QuantConv2d\n",
    "from brevitas.core.quant import QuantType\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "909fbc61-be07-409e-ba57-c9f298b91582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "577e9f4c-6021-43b2-af70-a4a547dc552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                           train = True,\n",
    "                                           transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
    "                                           download = True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                          train = False,\n",
    "                                          transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                                          download=True)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c5eb68-4d3c-444d-8141-8ce051053e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet_Quant(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Lenet_Quant, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "        QuantConv2d(1, 6, kernel_size=(5,5), bias=False), #stride =1 padding = 0 by default\n",
    "        BatchNorm2d(6),\n",
    "        QuantReLU(),\n",
    "        MaxPool2d(kernel_size =2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(QuantConv2d(6, 16, kernel_size = (5,5), bias = False),\n",
    "        BatchNorm2d(16),\n",
    "        QuantReLU(),\n",
    "        MaxPool2d(kernel_size=2, stride =2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "        QuantLinear(400, 120, bias = False),\n",
    "        QuantReLU(),\n",
    "        QuantLinear(120, 84, bias = False),\n",
    "        QuantReLU(),\n",
    "        QuantLinear(84, num_classes, bias = False))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.layer3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc057c28-43aa-47fc-89ec-5c5b76542a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_model = Lenet_Quant(num_classes).to(device)\n",
    "\n",
    "#Setting the loss function\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "#Setting the optimizer with the model parameters and learning rate\n",
    "optimizer = torch.optim.Adam(quant_model.parameters(), lr=learning_rate)\n",
    "\n",
    "#this is defined to print how many steps are remaining when training\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3145195-ea4c-4e69-a777-cd4d95d8aba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [400/938], Loss: 0.1300\n",
      "Epoch [1/10], Step [800/938], Loss: 0.0725\n",
      "Epoch [2/10], Step [400/938], Loss: 0.0083\n",
      "Epoch [2/10], Step [800/938], Loss: 0.0063\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0469\n",
      "Epoch [3/10], Step [800/938], Loss: 0.1000\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0004\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0012\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0500\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0126\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0018\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0033\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0100\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0226\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0200\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0431\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0074\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0044\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0033\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = quant_model(images)\n",
    "        loss = cost(outputs, labels)\n",
    "        \t\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \t\t\n",
    "        if (i+1) % 400 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35eb5bdf-e7d9-4235-b74a-8aa5bf37d0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 99.07 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "  \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = quant_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b60b126d-c329-41f4-97e3-32c0f75315d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(quant_model.state_dict(), \"qlenet5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7022fa81-772d-4849-aee6-9c720f0e0cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73c0fcc9-443e-40e4-84cc-89c95b7d6e34",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'brevitas.onnx' has no attribute 'export_finn_onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m export_onnx_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLenet5_Quant.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m bo\u001b[38;5;241m.\u001b[39mexport_finn_onnx(quant_model, input_shape, export_onnx_path)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'brevitas.onnx' has no attribute 'export_finn_onnx'"
     ]
    }
   ],
   "source": [
    "#Export to Onnx\n",
    "import brevitas.onnx as bo\n",
    "from brevitas.export import FINN_MANAGER\n",
    "export_onnx_path = \"Lenet5_Quant.onnx\"\n",
    "input_shape = (1, 1, 32, 32)\n",
    "bo.export_finn_onnx(quant_model, input_shape, export_onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da845c1-72ab-4c39-b682-a6d5c5660b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33c1d9-03e6-492a-9205-44403a704104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
